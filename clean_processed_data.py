#!/usr/bin/env python3
"""
Clean Processed Data Script
============================
Removes all intermediate and result files generated by the data collection pipeline,
leaving only the raw input data intact.

This script is useful for:
- Resetting the pipeline to reprocess data
- Cleaning up before archiving raw data
- Freeing disk space by removing generated files

Usage:
    python clean_processed_data.py --data-dir <path_to_data_directory>
    python clean_processed_data.py --data-dir data/_0118_bi_pick_and_place --dry-run
    python clean_processed_data.py --config config/VB_task_config.yaml

Author: Data Collection Pipeline
Date: January 2026
"""

import argparse
import shutil
from pathlib import Path
from typing import List, Tuple
import sys


def get_removable_items(data_dir: Path) -> Tuple[List[Path], List[Path]]:
    """
    Identify all intermediate and result files/directories to be removed.
    
    Args:
        data_dir: Root data directory (e.g., data/_0118_bi_pick_and_place)
    
    Returns:
        Tuple of (files_to_remove, dirs_to_remove)
    """
    files_to_remove = []
    dirs_to_remove = []
    
    # Top-level files to remove
    top_level_files = [
        'dataset_plan.pkl',
        '*.zarr.zip',
        '*.zarr',
    ]
    
    for pattern in top_level_files:
        if '*' in pattern:
            files_to_remove.extend(data_dir.glob(pattern))
        else:
            file_path = data_dir / pattern
            if file_path.exists():
                files_to_remove.append(file_path)
    
    # Demo-level intermediate files/directories
    demos_dir = data_dir / 'demos'
    if demos_dir.exists():
        for demo_dir in demos_dir.iterdir():
            if not demo_dir.is_dir():
                continue
            
            # Directories to remove
            demo_dirs_to_remove = [
                'cropped_img',
                'pose_data',
            ]
            
            for dir_name in demo_dirs_to_remove:
                dir_path = demo_dir / dir_name
                if dir_path.exists() and dir_path.is_dir():
                    dirs_to_remove.append(dir_path)
            
            # Files to remove
            demo_files_to_remove = [
                'gripper_width_left.csv',
                'gripper_width_right.csv',
            ]
            
            for file_name in demo_files_to_remove:
                file_path = demo_dir / file_name
                if file_path.exists():
                    files_to_remove.append(file_path)
    
    return files_to_remove, dirs_to_remove


def get_size_str(size_bytes: int) -> str:
    """Convert bytes to human-readable string."""
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.2f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.2f} PB"


def get_dir_size(path: Path) -> int:
    """Calculate total size of a directory."""
    total = 0
    try:
        for item in path.rglob('*'):
            if item.is_file():
                total += item.stat().st_size
    except Exception as e:
        print(f"  Warning: Could not calculate size for {path}: {e}")
    return total


def get_file_size(path: Path) -> int:
    """Get size of a file."""
    try:
        return path.stat().st_size
    except Exception as e:
        print(f"  Warning: Could not get size for {path}: {e}")
        return 0


def clean_data(data_dir: Path, dry_run: bool = False, verbose: bool = True) -> Tuple[int, int]:
    """
    Clean intermediate and result files from data directory.
    
    Args:
        data_dir: Root data directory
        dry_run: If True, only show what would be deleted without actually deleting
        verbose: If True, print detailed information
    
    Returns:
        Tuple of (files_removed_count, total_bytes_freed)
    """
    if not data_dir.exists():
        print(f"Error: Data directory does not exist: {data_dir}")
        return 0, 0
    
    print(f"\n{'='*60}")
    print(f"Scanning directory: {data_dir}")
    print(f"Mode: {'DRY RUN (no files will be deleted)' if dry_run else 'LIVE (files will be deleted)'}")
    print(f"{'='*60}\n")
    
    files_to_remove, dirs_to_remove = get_removable_items(data_dir)
    
    if not files_to_remove and not dirs_to_remove:
        print("✓ No intermediate or result files found. Directory is clean!")
        return 0, 0
    
    # Calculate total size
    total_size = 0
    for file_path in files_to_remove:
        total_size += get_file_size(file_path)
    for dir_path in dirs_to_remove:
        total_size += get_dir_size(dir_path)
    
    # Display summary
    print(f"Found items to remove:")
    print(f"  - Files: {len(files_to_remove)}")
    print(f"  - Directories: {len(dirs_to_remove)}")
    print(f"  - Total size: {get_size_str(total_size)}")
    print()
    
    if verbose:
        print("Files to be removed:")
        for file_path in sorted(files_to_remove):
            rel_path = file_path.relative_to(data_dir)
            size = get_file_size(file_path)
            print(f"  - {rel_path} ({get_size_str(size)})")
        
        if files_to_remove and dirs_to_remove:
            print()
        
        print("Directories to be removed:")
        for dir_path in sorted(dirs_to_remove):
            rel_path = dir_path.relative_to(data_dir)
            size = get_dir_size(dir_path)
            file_count = sum(1 for _ in dir_path.rglob('*') if _.is_file())
            print(f"  - {rel_path}/ ({file_count} files, {get_size_str(size)})")
        print()
    
    if dry_run:
        print("DRY RUN: No files were deleted.")
        return len(files_to_remove) + len(dirs_to_remove), total_size
    
    # Perform deletion
    print("Removing files and directories...")
    removed_count = 0
    errors = []
    
    # Remove files first
    for file_path in files_to_remove:
        try:
            file_path.unlink()
            removed_count += 1
            if verbose:
                print(f"  ✓ Removed: {file_path.relative_to(data_dir)}")
        except Exception as e:
            error_msg = f"Failed to remove {file_path.relative_to(data_dir)}: {e}"
            errors.append(error_msg)
            if verbose:
                print(f"  ✗ {error_msg}")
    
    # Remove directories
    for dir_path in dirs_to_remove:
        try:
            shutil.rmtree(dir_path)
            removed_count += 1
            if verbose:
                print(f"  ✓ Removed: {dir_path.relative_to(data_dir)}/")
        except Exception as e:
            error_msg = f"Failed to remove {dir_path.relative_to(data_dir)}: {e}"
            errors.append(error_msg)
            if verbose:
                print(f"  ✗ {error_msg}")
    
    print()
    print(f"{'='*60}")
    print(f"Cleanup complete!")
    print(f"  - Items removed: {removed_count}")
    print(f"  - Space freed: {get_size_str(total_size)}")
    if errors:
        print(f"  - Errors: {len(errors)}")
        print("\nErrors encountered:")
        for error in errors:
            print(f"  - {error}")
    print(f"{'='*60}\n")
    
    return removed_count, total_size


def load_config_file(config_path: Path) -> Path:
    """
    Load data directory path from config file.
    
    Args:
        config_path: Path to VB_task_config.yaml
    
    Returns:
        Path to data directory
    """
    try:
        import yaml
    except ImportError:
        print("Error: PyYAML is required to read config files.")
        print("Install it with: pip install pyyaml")
        sys.exit(1)
    
    if not config_path.exists():
        print(f"Error: Config file not found: {config_path}")
        sys.exit(1)
    
    try:
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        # Extract data directory and task name from config
        # The config structure is: recorder.output + task.name
        recorder_output = config.get('recorder', {}).get('output')
        task_name = config.get('task', {}).get('name')
        
        if not recorder_output or not task_name:
            print("Error: Could not extract 'recorder.output' and 'task.name' from config file")
            print(f"  recorder.output: {recorder_output}")
            print(f"  task.name: {task_name}")
            sys.exit(1)
        
        # Combine output directory and task name
        base_path = Path(recorder_output)
        if not base_path.is_absolute():
            # Resolve relative to the parent of config (the data_collection directory)
            base_path = (config_path.parent.parent / base_path).resolve()
        
        data_path = base_path / task_name
        
        return data_path
    
    except Exception as e:
        print(f"Error reading config file: {e}")
        sys.exit(1)


def main():
    parser = argparse.ArgumentParser(
        description='Clean intermediate and result files from data collection pipeline',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Dry run to see what would be deleted
  python clean_processed_data.py --data-dir data/_0118_bi_pick_and_place --dry-run

  # Actually delete files
  python clean_processed_data.py --data-dir data/_0118_bi_pick_and_place

  # Use config file to determine data directory
  python clean_processed_data.py --config config/VB_task_config.yaml

  # Quiet mode (less verbose)
  python clean_processed_data.py --data-dir data/_0118_bi_pick_and_place --quiet

Files/directories that will be removed:
  - dataset_plan.pkl (top level)
  - *.zarr.zip (top level)
  - *.zarr/ (top level)
  - demos/*/cropped_img/ (per demo)
  - demos/*/pose_data/ (per demo)
  - demos/*/gripper_width_*.csv (per demo)

Raw data that will be preserved:
  - demos/*/all_trajectory/
  - demos/*/left_hand_img/
  - demos/*/right_hand_img/
  - demos/*/metadata.json
        """
    )
    
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument(
        '--data-dir',
        type=Path,
        help='Path to data directory (e.g., data/_0118_bi_pick_and_place)'
    )
    group.add_argument(
        '--config',
        type=Path,
        help='Path to config YAML file (will extract data_dir from it)'
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Show what would be deleted without actually deleting'
    )
    parser.add_argument(
        '--quiet', '-q',
        action='store_true',
        help='Less verbose output (only show summary)'
    )
    parser.add_argument(
        '--yes', '-y',
        action='store_true',
        help='Skip confirmation prompt'
    )
    
    args = parser.parse_args()
    
    # Determine data directory
    if args.config:
        data_dir = load_config_file(args.config)
    else:
        data_dir = args.data_dir.resolve()
    
    # Confirmation prompt (unless --yes or --dry-run)
    if not args.dry_run and not args.yes:
        print(f"\nWARNING: This will permanently delete intermediate and result files from:")
        print(f"  {data_dir}")
        print("\nRaw data (images, trajectory JSON) will be preserved.")
        response = input("\nContinue? [y/N]: ").strip().lower()
        if response not in ['y', 'yes']:
            print("Aborted.")
            return
    
    # Perform cleanup
    verbose = not args.quiet
    removed_count, bytes_freed = clean_data(data_dir, dry_run=args.dry_run, verbose=verbose)
    
    if args.dry_run and removed_count > 0:
        print("\nTo actually delete these files, run without --dry-run:")
        print(f"  python {Path(__file__).name} --data-dir {data_dir}")


if __name__ == '__main__':
    main()
